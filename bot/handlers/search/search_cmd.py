from aiogram.types import Message
from pathlib import Path
from core.scraping import scrape_ads
from core.constants import DATA_DIR

async def search_cmd(message: Message):
    if not message.text:
        await message.reply(
            "âš ï¸ <b>Usage</b> : /search &lt;url&gt; &lt;nombre_de_pages&gt;",
            parse_mode="HTML",
        )
        return
    
    try:
        _, url, page = message.text.split(maxsplit=2)
        page_int = int(page)
    except ValueError:
        await message.reply(
            "âš ï¸ <b>Usage</b> : /search &lt;url&gt; &lt;nombre_de_pages&gt;",
            parse_mode="HTML",
        )
        return
    
    # Supprimer les anciennes donnÃ©es avant de commencer le nouveau scraping
    data_dir = DATA_DIR
    if data_dir.exists():
        # Supprimer tous les fichiers ads_*.json
        files_to_delete = list(data_dir.glob("ads_*.json"))
        
        if files_to_delete:
            deleted_count = 0
            for file_path in files_to_delete:
                try:
                    file_path.unlink()
                    deleted_count += 1
                except Exception as e:
                    print(f"Erreur lors de la suppression de {file_path}: {e}")
            
            await message.reply(
                f"ğŸ—‘ï¸ {deleted_count} anciens fichiers supprimÃ©s. DÃ©but du nouveau scraping...",
                parse_mode="HTML",
            )
        else:
            await message.reply("ğŸ”„ DÃ©but du scraping...", parse_mode="HTML")
    else:
        data_dir.mkdir(parents=True, exist_ok=True)
        await message.reply(
            "ğŸ”„ CrÃ©ation du rÃ©pertoire de donnÃ©es et dÃ©but du scraping...",
            parse_mode="HTML",
        )
    
    # Lancer le scraping
    count = len(scrape_ads(url, page_int))
    if count:
        await message.reply(
            f"âœ… <b>Recherche terminÃ©e</b> : {count} annonces trouvÃ©es pour {page_int} pages",
            parse_mode="HTML",
        )
    else:
        await message.reply(
            "âŒ Aucune annonce trouvÃ©e. VÃ©rifie l'URL ou rÃ©essaie plus tard.",
            parse_mode="HTML",
        )